{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the h5pyd package as h5py\n",
    "## resource for code (https://github.com/NREL/hsds-examples/tree/master)\n",
    "import h5pyd as h5py\n",
    "\n",
    "## other helpful packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alaska', 'Atlantic', 'Hawaii', 'West_Coast', 'maine', 'virtual_buoy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the contents of the directory\n",
    "folder = h5py.Folder(\"/nrel/US_wave/\", bucket=\"nrel-pds-hsds\")\n",
    "list(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Atlantic_wave_1979.h5',\n",
       " 'Atlantic_wave_1980.h5',\n",
       " 'Atlantic_wave_1981.h5',\n",
       " 'Atlantic_wave_1982.h5',\n",
       " 'Atlantic_wave_1983.h5',\n",
       " 'Atlantic_wave_1984.h5',\n",
       " 'Atlantic_wave_1985.h5',\n",
       " 'Atlantic_wave_1986.h5',\n",
       " 'Atlantic_wave_1987.h5',\n",
       " 'Atlantic_wave_1988.h5',\n",
       " 'Atlantic_wave_1989.h5',\n",
       " 'Atlantic_wave_1990.h5',\n",
       " 'Atlantic_wave_1991.h5',\n",
       " 'Atlantic_wave_1992.h5',\n",
       " 'Atlantic_wave_1993.h5',\n",
       " 'Atlantic_wave_1994.h5',\n",
       " 'Atlantic_wave_1995.h5',\n",
       " 'Atlantic_wave_1996.h5',\n",
       " 'Atlantic_wave_1997.h5',\n",
       " 'Atlantic_wave_1998.h5',\n",
       " 'Atlantic_wave_1999.h5',\n",
       " 'Atlantic_wave_2000.h5',\n",
       " 'Atlantic_wave_2001.h5',\n",
       " 'Atlantic_wave_2002.h5',\n",
       " 'Atlantic_wave_2003.h5',\n",
       " 'Atlantic_wave_2004.h5',\n",
       " 'Atlantic_wave_2005.h5',\n",
       " 'Atlantic_wave_2006.h5',\n",
       " 'Atlantic_wave_2007.h5',\n",
       " 'Atlantic_wave_2008.h5',\n",
       " 'Atlantic_wave_2009.h5',\n",
       " 'Atlantic_wave_2010.h5']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlantic = h5py.Folder(\"/nrel/US_wave/Atlantic/\", bucket=\"nrel-pds-hsds\")\n",
    "list(atlantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***note: code does not work on computer, but hsls should list contents within the Puerto Rico folder\n",
    "! hsls -H -v --bucket nrel-pds-hsds /nrel/nsrdb/puerto_rico/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets from WindToolkit (https://github.com/NREL/hsds-examples/blob/master/datasets/wtk-us.md)\n",
    "## data exist between 2001 and 2020\n",
    "# f01 = h5py.File(\"/nrel/wtk/pr100/5min/puerto_rico_wind_5min_2001.h5\")\n",
    "# f02 = h5py.File(\"/nrel/wtk/pr100/5min/puerto_rico_wind_5min_2002.h5\")\n",
    "# f03 = h5py.File(\"/nrel/wtk/pr100/5min/puerto_rico_wind_5min_2003.h5\")\n",
    "# f04 = h5py.File(\"/nrel/wtk/pr100/5min/puerto_rico_wind_5min_2004.h5\")\n",
    "# f05 = h5py.File(\"/nrel/wtk/pr100/5min/puerto_rico_wind_5min_2005.h5\")\n",
    "# f06 = h5py.File(\"/nrel/wtk/pr100/5min/puerto_rico_wind_5min_2006.h5\")\n",
    "f07 = h5py.File(\"/nrel/US_wave/Atlantic/Atlantic_wave_2007.h5\")\n",
    "# f08 = h5py.File(\"/nrel/wtk/pr100/5min/puerto_rico_wind_5min_2008.h5\")\n",
    "# f09 = h5py.File(\"/nrel/wtk/pr100/5min/puerto_rico_wind_5min_2009.h5\")\n",
    "# f10 = h5py.File(\"/nrel/wtk/pr100/5min/puerto_rico_wind_5min_2010.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coordinates',\n",
       " 'directionality_coefficient',\n",
       " 'energy_period',\n",
       " 'maximum_energy_direction',\n",
       " 'mean_absolute_period',\n",
       " 'mean_wave_direction',\n",
       " 'mean_zero-crossing_period',\n",
       " 'meta',\n",
       " 'omni-directional_wave_power',\n",
       " 'peak_period',\n",
       " 'significant_wave_height',\n",
       " 'spectral_width',\n",
       " 'time_index',\n",
       " 'water_depth']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the datasets within each year's file\n",
    "list(f07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data important for this work are: coordinates (for each site) and wind speed at 160m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>water_depth</th>\n",
       "      <th>timezone</th>\n",
       "      <th>distance</th>\n",
       "      <th>jurisdiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.564098</td>\n",
       "      <td>-75.976997</td>\n",
       "      <td>1.3426</td>\n",
       "      <td>-5</td>\n",
       "      <td>647.230042</td>\n",
       "      <td>b'Maryland'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.565899</td>\n",
       "      <td>-75.977997</td>\n",
       "      <td>1.3118</td>\n",
       "      <td>-5</td>\n",
       "      <td>432.485596</td>\n",
       "      <td>b'Maryland'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.566101</td>\n",
       "      <td>-75.980003</td>\n",
       "      <td>1.2325</td>\n",
       "      <td>-5</td>\n",
       "      <td>320.273590</td>\n",
       "      <td>b'Maryland'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.562302</td>\n",
       "      <td>-75.976997</td>\n",
       "      <td>1.3392</td>\n",
       "      <td>-5</td>\n",
       "      <td>685.832764</td>\n",
       "      <td>b'Maryland'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.563900</td>\n",
       "      <td>-75.978996</td>\n",
       "      <td>1.3020</td>\n",
       "      <td>-5</td>\n",
       "      <td>574.726929</td>\n",
       "      <td>b'Maryland'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude  longitude  water_depth  timezone    distance jurisdiction\n",
       "0  39.564098 -75.976997       1.3426        -5  647.230042  b'Maryland'\n",
       "1  39.565899 -75.977997       1.3118        -5  432.485596  b'Maryland'\n",
       "2  39.566101 -75.980003       1.2325        -5  320.273590  b'Maryland'\n",
       "3  39.562302 -75.976997       1.3392        -5  685.832764  b'Maryland'\n",
       "4  39.563900 -75.978996       1.3020        -5  574.726929  b'Maryland'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the metadata\n",
    "meta07 = pd.DataFrame(f07['meta'][...])\n",
    "meta07.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'Federal',\n",
       " b'Massachusetts',\n",
       " b'Connecticut',\n",
       " b'Maine',\n",
       " b'New York',\n",
       " b'New Hampshire',\n",
       " b'Delaware',\n",
       " b'Canada',\n",
       " b'Rhode Island',\n",
       " b'Virginia',\n",
       " b'Florida',\n",
       " b'Bahamas',\n",
       " b'Georgia',\n",
       " b'South Carolina',\n",
       " b'Maryland',\n",
       " b'New Jersey',\n",
       " b'North Carolina']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values_set = set(meta07['jurisdiction'])\n",
    "list(unique_values_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the attributes for the datasets and determine the scale factor and units\n",
    "list(f01['windspeed_160m'].attrs)\n",
    "\n",
    "# inspect shape, type, etc.\n",
    "print(f01['windspeed_160m'].shape)\n",
    "\n",
    "## display the scale factor (100) and units (meters per second)\n",
    "print(f01['windspeed_160m'].attrs['scale_factor'])\n",
    "print(f01['windspeed_160m'].attrs['units'])\n",
    "\n",
    "# set the scale factor value\n",
    "sf = f01['windspeed_160m'].attrs['scale_factor']\n",
    "print(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the wind speed data for each year\n",
    "\n",
    "%time\n",
    "\n",
    "wind01 = pd.DataFrame(f01['windspeed_160m'][...]) / sf\n",
    "wind02 = pd.DataFrame(f02['windspeed_160m'][...]) / sf\n",
    "wind03 = pd.DataFrame(f03['windspeed_160m'][...]) / sf\n",
    "wind04 = pd.DataFrame(f04['windspeed_160m'][...]) / sf\n",
    "wind05 = pd.DataFrame(f05['windspeed_160m'][...]) / sf\n",
    "wind06 = pd.DataFrame(f06['windspeed_160m'][...]) / sf\n",
    "wind07 = pd.DataFrame(f07['windspeed_160m'][...]) / sf\n",
    "wind08 = pd.DataFrame(f08['windspeed_160m'][...]) / sf\n",
    "wind09 = pd.DataFrame(f09['windspeed_160m'][...]) / sf\n",
    "wind10 = pd.DataFrame(f10['windspeed_160m'][...]) / sf\n",
    "wind11 = pd.DataFrame(f11['windspeed_160m'][...]) / sf\n",
    "wind12 = pd.DataFrame(f12['windspeed_160m'][...]) / sf\n",
    "wind13 = pd.DataFrame(f13['windspeed_160m'][...]) / sf\n",
    "wind14 = pd.DataFrame(f14['windspeed_160m'][...]) / sf\n",
    "wind15 = pd.DataFrame(f15['windspeed_160m'][...]) / sf\n",
    "wind16 = pd.DataFrame(f16['windspeed_160m'][...]) / sf\n",
    "wind17 = pd.DataFrame(f17['windspeed_160m'][...]) / sf\n",
    "wind18 = pd.DataFrame(f18['windspeed_160m'][...]) / sf\n",
    "wind19 = pd.DataFrame(f19['windspeed_160m'][...]) / sf\n",
    "wind20 = pd.DataFrame(f20['windspeed_160m'][...]) / sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save wind data to csv\n",
    "wind01.to_csv('pr_wind01.csv')\n",
    "wind02.to_csv('pr_wind02.csv')\n",
    "wind03.to_csv('pr_wind03.csv')\n",
    "wind04.to_csv('pr_wind04.csv')\n",
    "wind05.to_csv('pr_wind05.csv')\n",
    "wind06.to_csv('pr_wind06.csv')\n",
    "wind07.to_csv('pr_wind07.csv')\n",
    "wind08.to_csv('pr_wind08.csv')\n",
    "wind09.to_csv('pr_wind09.csv')\n",
    "wind10.to_csv('pr_wind10.csv')\n",
    "wind11.to_csv('pr_wind11.csv')\n",
    "wind12.to_csv('pr_wind12.csv')\n",
    "wind13.to_csv('pr_wind13.csv')\n",
    "wind14.to_csv('pr_wind14.csv')\n",
    "wind15.to_csv('pr_wind15.csv')\n",
    "wind16.to_csv('pr_wind16.csv')\n",
    "wind17.to_csv('pr_wind17.csv')\n",
    "wind18.to_csv('pr_wind18.csv')\n",
    "wind19.to_csv('pr_wind19.csv')\n",
    "wind20.to_csv('pr_wind20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the coordinates data for each year\n",
    "\n",
    "%time\n",
    "\n",
    "coords01 = pd.DataFrame(f01['coordinates'][...])\n",
    "coords02 = pd.DataFrame(f02['coordinates'][...])\n",
    "coords03 = pd.DataFrame(f03['coordinates'][...])\n",
    "coords04 = pd.DataFrame(f04['coordinates'][...])\n",
    "coords05 = pd.DataFrame(f05['coordinates'][...])\n",
    "coords06 = pd.DataFrame(f06['coordinates'][...])\n",
    "coords07 = pd.DataFrame(f07['coordinates'][...])\n",
    "coords08 = pd.DataFrame(f08['coordinates'][...])\n",
    "coords09 = pd.DataFrame(f09['coordinates'][...])\n",
    "coords10 = pd.DataFrame(f10['coordinates'][...])\n",
    "coords11 = pd.DataFrame(f11['coordinates'][...])\n",
    "coords12 = pd.DataFrame(f12['coordinates'][...])\n",
    "coords13 = pd.DataFrame(f13['coordinates'][...])\n",
    "coords14 = pd.DataFrame(f14['coordinates'][...])\n",
    "coords15 = pd.DataFrame(f15['coordinates'][...])\n",
    "coords16 = pd.DataFrame(f16['coordinates'][...])\n",
    "coords17 = pd.DataFrame(f17['coordinates'][...])\n",
    "coords18 = pd.DataFrame(f18['coordinates'][...])\n",
    "coords19 = pd.DataFrame(f19['coordinates'][...])\n",
    "coords20 = pd.DataFrame(f20['coordinates'][...])\n",
    "\n",
    "# # inspect dataset shapes to verify they are the same dimensions\n",
    "# print(coords01)\n",
    "# coords01, coords02, coords03, coords04, coords05, coords06, coords07, coords08, coords09, coords10, \\\n",
    "#     coords11, coords12, coords13, coords14, coords15, coords16, coords17, coords18, coords19, coords20 \n",
    "\n",
    "coords01 = coords01.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords02 = coords02.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords03 = coords03.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords04 = coords04.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords05 = coords05.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords06 = coords06.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords07 = coords07.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords08 = coords08.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords09 = coords09.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords10 = coords10.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords11 = coords11.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords12 = coords12.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords13 = coords13.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords14 = coords14.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords15 = coords15.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords16 = coords16.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords17 = coords17.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords18 = coords18.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords19 = coords19.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "coords20 = coords20.rename(columns={0: \"lat\", 1: \"long\"})\n",
    "\n",
    "print(coords01.head(), coords02.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the coordinate data as csv files\n",
    "\n",
    "coords01.to_csv(\"wind01_coords.csv\")\n",
    "coords02.to_csv(\"wind02_coords.csv\")\n",
    "coords03.to_csv(\"wind03_coords.csv\")\n",
    "coords04.to_csv(\"wind04_coords.csv\")\n",
    "coords05.to_csv(\"wind05_coords.csv\")\n",
    "coords06.to_csv(\"wind06_coords.csv\")\n",
    "coords07.to_csv(\"wind07_coords.csv\")\n",
    "coords08.to_csv(\"wind08_coords.csv\")\n",
    "coords09.to_csv(\"wind09_coords.csv\")\n",
    "coords10.to_csv(\"wind10_coords.csv\")\n",
    "coords11.to_csv(\"wind11_coords.csv\")\n",
    "coords12.to_csv(\"wind12_coords.csv\")\n",
    "coords13.to_csv(\"wind13_coords.csv\")\n",
    "coords14.to_csv(\"wind14_coords.csv\")\n",
    "coords15.to_csv(\"wind15_coords.csv\")\n",
    "coords16.to_csv(\"wind16_coords.csv\")\n",
    "coords17.to_csv(\"wind17_coords.csv\")\n",
    "coords18.to_csv(\"wind18_coords.csv\")\n",
    "coords19.to_csv(\"wind19_coords.csv\")\n",
    "coords20.to_csv(\"wind20_coords.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual averages of each site\n",
    "avg01 = np.transpose(pd.DataFrame(wind01.mean(axis = 0)))\n",
    "avg02 = np.transpose(pd.DataFrame(wind02.mean(axis = 0)))\n",
    "avg03 = np.transpose(pd.DataFrame(wind03.mean(axis = 0)))\n",
    "avg04 = np.transpose(pd.DataFrame(wind04.mean(axis = 0)))\n",
    "avg05 = np.transpose(pd.DataFrame(wind05.mean(axis = 0)))\n",
    "avg06 = np.transpose(pd.DataFrame(wind06.mean(axis = 0)))\n",
    "avg07 = np.transpose(pd.DataFrame(wind07.mean(axis = 0)))\n",
    "avg08 = np.transpose(pd.DataFrame(wind08.mean(axis = 0)))\n",
    "avg09 = np.transpose(pd.DataFrame(wind09.mean(axis = 0)))\n",
    "avg10 = np.transpose(pd.DataFrame(wind10.mean(axis = 0)))\n",
    "avg11 = np.transpose(pd.DataFrame(wind11.mean(axis = 0)))\n",
    "avg12 = np.transpose(pd.DataFrame(wind12.mean(axis = 0)))\n",
    "avg13 = np.transpose(pd.DataFrame(wind13.mean(axis = 0)))\n",
    "avg14 = np.transpose(pd.DataFrame(wind14.mean(axis = 0)))\n",
    "avg15 = np.transpose(pd.DataFrame(wind15.mean(axis = 0)))\n",
    "avg16 = np.transpose(pd.DataFrame(wind16.mean(axis = 0)))\n",
    "avg17 = np.transpose(pd.DataFrame(wind17.mean(axis = 0)))\n",
    "avg18 = np.transpose(pd.DataFrame(wind18.mean(axis = 0)))\n",
    "avg19 = np.transpose(pd.DataFrame(wind19.mean(axis = 0)))\n",
    "avg20 = np.transpose(pd.DataFrame(wind20.mean(axis = 0)))\n",
    "\n",
    "print(avg01.head())\n",
    "print(avg01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the averaged annual data as CSV files\n",
    "\n",
    "avg01.to_csv(\"wind01_avg.csv\")\n",
    "avg02.to_csv(\"wind02_avg.csv\")\n",
    "avg03.to_csv(\"wind03_avg.csv\")\n",
    "avg04.to_csv(\"wind04_avg.csv\")\n",
    "avg05.to_csv(\"wind05_avg.csv\")\n",
    "avg06.to_csv(\"wind06_avg.csv\")\n",
    "avg07.to_csv(\"wind07_avg.csv\")\n",
    "avg08.to_csv(\"wind08_avg.csv\")\n",
    "avg09.to_csv(\"wind09_avg.csv\")\n",
    "avg10.to_csv(\"wind10_avg.csv\")\n",
    "avg11.to_csv(\"wind11_avg.csv\")\n",
    "avg12.to_csv(\"wind12_avg.csv\")\n",
    "avg13.to_csv(\"wind13_avg.csv\")\n",
    "avg14.to_csv(\"wind14_avg.csv\")\n",
    "avg15.to_csv(\"wind15_avg.csv\")\n",
    "avg16.to_csv(\"wind16_avg.csv\")\n",
    "avg17.to_csv(\"wind17_avg.csv\")\n",
    "avg18.to_csv(\"wind18_avg.csv\")\n",
    "avg19.to_csv(\"wind19_avg.csv\")\n",
    "avg20.to_csv(\"wind20_avg.csv\")\n",
    "\n",
    "# # export the average 20-year datasets as CSVs\n",
    "wind_avg.to_csv(\"wind_avg.csv\")\n",
    "twenty_wind_avg.to_csv(\"wind_01_20_avg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords01_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/b_coordinates/wind01_coords.csv', index_col=0)\n",
    "\n",
    "avg01_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind01_avg.csv', index_col=0)\n",
    "avg02_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind02_avg.csv', index_col=0)\n",
    "avg03_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind03_avg.csv', index_col=0)\n",
    "avg04_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind04_avg.csv', index_col=0)\n",
    "avg05_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind05_avg.csv', index_col=0)\n",
    "avg06_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind06_avg.csv', index_col=0)\n",
    "avg07_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind07_avg.csv', index_col=0)\n",
    "avg08_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind08_avg.csv', index_col=0)\n",
    "avg09_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind09_avg.csv', index_col=0)\n",
    "avg10_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind10_avg.csv', index_col=0)\n",
    "avg11_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind11_avg.csv', index_col=0)\n",
    "avg12_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind12_avg.csv', index_col=0)\n",
    "avg13_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind13_avg.csv', index_col=0)\n",
    "avg14_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind14_avg.csv', index_col=0)\n",
    "avg15_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind15_avg.csv', index_col=0)\n",
    "avg16_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind16_avg.csv', index_col=0)\n",
    "avg17_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind17_avg.csv', index_col=0)\n",
    "avg18_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind18_avg.csv', index_col=0)\n",
    "avg19_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind19_avg.csv', index_col=0)\n",
    "avg20_csv = pd.read_csv('/Users/Brian/Documents/Personal/Jobs/Past/CSS/NOAA/pr_wind_analysis/data/c_annual_average/wind20_avg.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coords01_csv, avg01_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_avg = pd.concat([avg01_csv,avg02_csv,avg03_csv,avg04_csv,avg05_csv,avg06_csv,avg07_csv,avg08_csv,avg09_csv,avg10_csv,avg11_csv,avg12_csv,avg13_csv,avg14_csv,avg15_csv,avg16_csv,avg17_csv,avg18_csv,avg19_csv,avg20_csv])\n",
    "twenty_wind_avg = pd.DataFrame(wind_avg.mean(axis=0))\n",
    "\n",
    "# wind_avg = pd.concat([wind_avg, year_wind], axis=1)\n",
    "print(twenty_wind_avg, coords01_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twenty_wind_avg.dtypes, coords01_csv.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the averaged 20-year dataset\n",
    "\n",
    "# add the coordinates to the 20-year dataset\n",
    "twenty_wind_coords = pd.concat([twenty_wind_avg, coords01_csv])\n",
    "\n",
    "# # rename the first column to have it be mean wind speed\n",
    "twenty_wind_coords = twenty_wind_coords.rename(columns = {0: \"mean_wind\"})\n",
    "\n",
    "# # rename the index name to indicate it is for the sites\n",
    "twenty_wind_coords.index.names = ['site']\n",
    "\n",
    "# # inspect the top of the dataset\n",
    "print(twenty_wind_coords)\n",
    "\n",
    "# # export the data as a CSV file\n",
    "twenty_wind_coords.to_csv(\"wind_01_20_avg_coords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr01 = arr01.mean(axis = 0)\n",
    "# arr02 = arr02.mean(axis = 0)\n",
    "# arr03 = arr03.mean(axis = 0)\n",
    "# arr04 = arr04.mean(axis = 0)\n",
    "# arr05 = arr05.mean(axis = 0)\n",
    "# arr06 = arr06.mean(axis = 0)\n",
    "# arr07 = arr07.mean(axis = 0)\n",
    "# arr08 = arr08.mean(axis = 0)\n",
    "# arr09 = arr09.mean(axis = 0)\n",
    "# arr10 = arr10.mean(axis = 0)\n",
    "# arr11 = arr11.mean(axis = 0)\n",
    "# arr12 = arr12.mean(axis = 0)\n",
    "# arr13 = arr13.mean(axis = 0)\n",
    "# arr14 = arr14.mean(axis = 0)\n",
    "# arr15 = arr15.mean(axis = 0)\n",
    "# arr16 = arr16.mean(axis = 0)\n",
    "# arr17 = arr17.mean(axis = 0)\n",
    "# arr18 = arr18.mean(axis = 0)\n",
    "# arr19 = arr19.mean(axis = 0)\n",
    "# arr20 = arr20.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg01 = np.transpose(pd.DataFrame(np.array(arr01)))\n",
    "# avg02 = np.transpose(pd.DataFrame(np.array(arr02)))\n",
    "# avg03 = np.transpose(pd.DataFrame(np.array(arr03)))\n",
    "# avg04 = np.transpose(pd.DataFrame(np.array(arr04)))\n",
    "# avg05 = np.transpose(pd.DataFrame(np.array(arr05)))\n",
    "# avg06 = np.transpose(pd.DataFrame(np.array(arr06)))\n",
    "# avg07 = np.transpose(pd.DataFrame(np.array(arr07)))\n",
    "# avg08 = np.transpose(pd.DataFrame(np.array(arr08)))\n",
    "# avg09 = np.transpose(pd.DataFrame(np.array(arr09)))\n",
    "# avg10 = np.transpose(pd.DataFrame(np.array(arr10)))\n",
    "# avg11 = np.transpose(pd.DataFrame(np.array(arr11)))\n",
    "# avg12 = np.transpose(pd.DataFrame(np.array(arr12)))\n",
    "# avg13 = np.transpose(pd.DataFrame(np.array(arr13)))\n",
    "# avg14 = np.transpose(pd.DataFrame(np.array(arr14)))\n",
    "# avg15 = np.transpose(pd.DataFrame(np.array(arr15)))\n",
    "# avg16 = np.transpose(pd.DataFrame(np.array(arr16)))\n",
    "# avg17 = np.transpose(pd.DataFrame(np.array(arr17)))\n",
    "# avg18 = np.transpose(pd.DataFrame(np.array(arr18)))\n",
    "# avg19 = np.transpose(pd.DataFrame(np.array(arr19)))\n",
    "# avg20 = np.transpose(pd.DataFrame(np.array(arr20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = list(range(2001, 2020))\n",
    "# years\n",
    "# year_wind = pd.DataFrame({'year': years})\n",
    "# print(year_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind_avg = pd.concat([avg01,avg02,avg03,avg04,avg05,avg06,avg07,avg08,avg09,avg10,avg11,avg12,avg13,avg14,avg15,avg16,avg17,avg18,avg19,avg20])\n",
    "# twenty_wind_avg = pd.DataFrame(wind_avg.mean(axis=0))\n",
    "# # wind_avg = pd.concat([wind_avg, year_wind], axis=1)\n",
    "# print(wind_avg)\n",
    "# print(twenty_wind_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     arr = dset[i,:]\n",
    "#     print(i,arr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_index = f[\"time_index\"]\n",
    "# time_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_index[0:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
